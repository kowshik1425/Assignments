{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means across two or more groups. To ensure the validity of ANOVA results, several assumptions must be met. Here are the key assumptions required to use ANOVA:\n",
    "\n",
    "Independence: Observations within each group must be independent of each other. This means that the value of one observation should not be influenced by the value of another observation within the same group.\n",
    "Normality: The data within each group should follow a normal distribution. This assumption ensures that the sampling distribution of the means is approximately normal, which is necessary for accurate hypothesis testing.\n",
    "Homogeneity of Variance (Homoscedasticity): The variances of the groups being compared should be approximately equal. In other words, the spread or dispersion of data points around the group means should be consistent across all groups.\n",
    "Equal Group Sizes (for one-way ANOVA): For one-way ANOVA (comparing means across multiple groups), it is preferable to have equal sample sizes in each group. However, ANOVA is robust to moderate deviations from equal group sizes, especially when sample sizes are large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459deef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "One-Way ANOVA:\n",
    "Use: One-way ANOVA is used when comparing means across two or more independent groups on a single continuous outcome variable.\n",
    "Situation: It is typically used in experimental designs with a single categorical independent variable (factor) and a continuous dependent variable. For example, comparing the mean exam scores of students taught using three different teaching methods (e.g., lecture, group discussion, online modules).\n",
    "Two-Way ANOVA:\n",
    "Use: Two-way ANOVA is used when comparing means across two categorical independent variables (factors) and their interactions on a single continuous outcome variable.\n",
    "Situation: It is suitable for experimental designs with two independent variables, each with two or more levels, and a continuous dependent variable. For example, comparing the mean exam scores of students taught using different teaching methods (e.g., lecture, group discussion) across different class sizes (e.g., small, medium, large).\n",
    "Repeated Measures ANOVA:\n",
    "Use: Repeated measures ANOVA is used when comparing means across two or more related groups on a single continuous outcome variable, where each participant or subject is measured under multiple conditions or time points.\n",
    "Situation: It is commonly used in longitudinal or repeated measures designs where the same participants are measured at multiple time points or under multiple experimental conditions. For example, comparing the mean scores of participants on a cognitive task before and after a training intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795daebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "Identify Sources of Variation: ANOVA allows researchers to partition the total variance in the data into variance components associated with different factors or sources of variation. This helps identify which factors are contributing significantly to the observed differences in the outcome variable.\n",
    "Assess the Relative Importance of Factors: By quantifying the amount of variance explained by each factor (e.g., main effects, interactions), researchers can assess the relative importance of different factors in influencing the outcome variable. This information is valuable for understanding the underlying processes or mechanisms driving the observed differences.\n",
    "Interpret and Generalize Results: Understanding the partitioning of variance enables researchers to interpret the results of ANOVA accurately and generalize findings to the broader population or context. It allows researchers to make inferences about the population parameters based on the sample data and assess the robustness of their conclusions.\n",
    "Guide Model Selection and Interpretation: Partitioning variance helps guide model selection and interpretation by identifying which factors should be included in the statistical model and how they should be modeled (e.g., main effects only, interaction effects). It informs decisions about model complexity and helps avoid overfitting or underfitting the data.\n",
    "Evaluate Model Fit and Assumptions: ANOVA involves fitting statistical models to the data, and understanding the partitioning of variance helps evaluate the adequacy of model fit and assumptions. It allows researchers to assess whether the model adequately captures the underlying structure of the data and whether the assumptions of ANOVA (e.g., normality, homogeneity of variance) are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebae118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "data = pd.read_csv('data.csv')\n",
    "y = data['Dependent_Variable']\n",
    "group_means = data.groupby('Independent_Variable').mean()['Dependent_Variable']\n",
    "\n",
    "grand_mean = np.mean(y)\n",
    "SST = np.sum((y - grand_mean)**2)\n",
    "SSE = np.sum((group_means - grand_mean)**2)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "data = pd.read_csv('data.csv')\n",
    "model = ols('Dependent_Variable ~ C(Independent_Variable1) + C(Independent_Variable2) + C(Independent_Variable1):C(Independent_Variable2)', data).fit()\n",
    "print(sm.stats.anova_lm(model, typ=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "Interpretation of the F-statistic:\n",
    "The F-statistic measures the ratio of the variance between groups (explained variance) to the variance within groups (unexplained variance). A larger F-statistic suggests greater differences between group means relative to the variability within groups.\n",
    "In this case, the obtained F-statistic of 5.23 indicates that the differences between the group means are 5.23 times larger than would be expected by chance variation alone.\n",
    "Interpretation of the p-value:\n",
    "The p-value associated with the F-statistic represents the probability of obtaining the observed F-statistic or a more extreme value under the null hypothesis (i.e., assuming no differences between group means).\n",
    "A p-value less than a chosen significance level (e.g., 0.05) indicates that the observed differences between group means are statistically significant, and we reject the null hypothesis in favor of the alternative hypothesis.\n",
    "In this case, the p-value of 0.02 indicates that the observed differences between group means are statistically significant at the 0.05 significance level.\n",
    "Conclusion:\n",
    "Based on the obtained F-statistic of 5.23 and the associated p-value of 0.02, we conclude that there are statistically significant differences between the groups.\n",
    "Rejecting the null hypothesis suggests that at least one group mean is different from the others. However, it does not provide information about which specific group(s) differ from each other.\n",
    "Further post-hoc tests (e.g., Tukey's HSD, Bonferroni correction) may be conducted to determine which groups differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34505c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "Complete Case Analysis (Listwise Deletion):\n",
    "Method: Exclude any cases with missing data on any variable included in the analysis.\n",
    "Consequences: This method can lead to loss of valuable information and reduced statistical power, especially if the missing data are not completely random. It may also introduce bias if the missing data mechanism is related to the outcome variable or other covariates.\n",
    "Mean/Median/Mode Imputation:\n",
    "Method: Replace missing values with the mean, median, or mode of the respective variable.\n",
    "Consequences: Imputation methods can artificially reduce variance and bias estimates, particularly if the missing data are not missing completely at random (MCAR). Imputing with central tendency measures can also distort the distribution of the variable and underestimate standard errors.\n",
    "Regression Imputation:\n",
    "Method: Predict missing values based on other observed variables using regression models.\n",
    "Consequences: Regression imputation can produce more accurate imputations compared to simple imputation methods but may introduce bias if the predictors used in the regression model are correlated with the missing variable or if the model assumptions are violated.\n",
    "Last Observation Carried Forward (LOCF):\n",
    "Method: Use the last observed value to replace missing values.\n",
    "Consequences: LOCF assumes that the missing values remain constant over time, which may not be valid in longitudinal or repeated measures designs. It can artificially inflate statistical power and bias estimates if the assumption is violated.\n",
    "Multiple Imputation:\n",
    "Method: Generate multiple imputed datasets with plausible values for missing data and pool results across imputations.\n",
    "Consequences: Multiple imputation provides more accurate estimates of parameters and standard errors compared to single imputation methods. However, it can be computationally intensive and requires specifying a model for imputation, which may not always be straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee70c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "Tukey's Honestly Significant Difference (HSD):\n",
    "Use: Tukey's HSD test compares all possible pairs of group means and determines whether their differences are statistically significant.\n",
    "When to use: Tukey's HSD is often used when there are multiple groups (more than two) in the ANOVA and you want to compare all pairwise differences between groups. It controls the family-wise error rate and is appropriate for balanced designs (equal group sizes).\n",
    "Bonferroni Correction:\n",
    "Use: The Bonferroni correction adjusts the significance level for multiple comparisons by dividing the desired significance level (e.g., 0.05) by the number of comparisons being made.\n",
    "When to use: Bonferroni correction is commonly used when conducting multiple pairwise comparisons to control the overall Type I error rate. It is conservative and appropriate for situations where a large number of comparisons are being made.\n",
    "Dunnett's Test:\n",
    "Use: Dunnett's test compares each treatment group to a control group or a reference group.\n",
    "When to use: Dunnett's test is used when there is a control group or a reference group, and you want to compare each treatment group to the control/reference group while controlling the overall Type I error rate.\n",
    "Scheffé's Test:\n",
    "Use: Scheffé's test compares all possible combinations of group means while controlling the overall Type I error rate.\n",
    "When to use: Scheffé's test is a conservative post-hoc test that can be used in situations where the assumption of equal variances is violated or when sample sizes are unequal. It is appropriate for both balanced and unbalanced designs.\n",
    "Fisher's Least Significant Difference (LSD):\n",
    "Use: Fisher's LSD test compares all possible pairs of group means without adjusting for multiple comparisons.\n",
    "When to use: Fisher's LSD test is not commonly recommended due to its lack of control over the overall Type I error rate. However, it may be used when conducting exploratory analyses or when the number of comparisons is small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66eb15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 13.204428926355243\n",
      "p-value: 5.322126419915365e-06\n",
      "The p-value is less than 0.05, indicating that there are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "np.random.seed(0)  \n",
    "weight_loss_A = np.random.normal(loc=5, scale=2, size=50)  \n",
    "weight_loss_B = np.random.normal(loc=4.5, scale=1.5, size=50)  \n",
    "weight_loss_C = np.random.normal(loc=6, scale=2.5, size=50)  \n",
    "f_statistic, p_value = f_oneway(weight_loss_A, weight_loss_B, weight_loss_C)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    print(\"The p-value is less than 0.05, indicating that there are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to 0.05, indicating that there are no significant differences between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A', 'B', 'C'] * 20,  \n",
    "    'Experience': ['Novice'] * 30 + ['Experienced'] * 30,\n",
    "    'Time': [25, 28, 27, 30, 32, 31, 22, 24, 23, 35, 37, 36, 28, 30, 29,\n",
    "             33, 35, 34, 20, 22, 21, 26, 28, 27, 32, 34, 33, 26, 28, 27,\n",
    "             40, 42, 41, 33, 35, 34, 25, 28, 27, 30, 32, 31, 22, 24, 23,\n",
    "             35, 37, 36, 28, 30, 29, 33, 35, 34, 20, 22, 21, 26, 28, 27,\n",
    "             32, 34, 33, 26, 28, 27, 40, 42, 41, 33, 35, 34]\n",
    "})\n",
    "data['Software'] = pd.Categorical(data['Software'])\n",
    "data['Experience'] = pd.Categorical(data['Experience'])\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data).fit()\n",
    "print(sm.stats.anova_lm(model, typ=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e9388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.597192759749614\n",
      "p-value: 0.0004062796020362504\n",
      "The p-value is less than 0.05, indicating that there are significant differences in test scores between the control and experimental groups.\n",
      "Since the results are significant, follow-up with a post-hoc test to determine which group(s) differ significantly from each other.\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "np.random.seed(0) \n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100) \n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100) \n",
    "t_statistic, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    print(\"The p-value is less than 0.05, indicating that there are significant differences in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to 0.05, indicating that there are no significant differences in test scores between the control and experimental groups.\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Since the results are significant, follow-up with a post-hoc test to determine which group(s) differ significantly from each other.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "data = pd.DataFrame({\n",
    "    'Day': list(range(1, 31)) * 3, \n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Sales': [100, 110, 105, 95, 105, 100, 115, 105, 110, 105, 115, 120, 90, 100, 95,\n",
    "              85, 90, 85, 80, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130,\n",
    "              150, 155, 160, 150, 145, 140, 135, 140, 145, 140, 135, 130, 125, 120, 115,\n",
    "              120, 125, 130, 135, 140, 145, 150, 155, 160]\n",
    "})\n",
    "data['Store'] = pd.Categorical(data['Store'])\n",
    "model = ols('Sales ~ C(Store) + C(Day)', data).fit()\n",
    "print(sm.stats.anova_lm(model, typ=2))\n",
    "print(\"Since the results are significant, follow-up with a post-hoc test to determine which store(s) differ significantly from each other.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc40163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
