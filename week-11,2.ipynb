{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546bd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Probability Mass Function (PMF):\n",
    "A PMF is a function that assigns probabilities to discrete random variables. It describes the probability that a discrete random variable takes on a specific value. In other words, it gives you the probability of each possible outcome.\n",
    "\n",
    "Example: Rolling a Fair Six-Sided Die\n",
    "Let's say you roll a fair six-sided die. The possible outcomes are the integers 1 through 6. The PMF for this scenario would look like this:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6\n",
    "Each line in the PMF represents the probability of rolling a specific number on the die. Since the die is fair, each outcome has an equal probability of 1/6.\n",
    "\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "A PDF is a function that describes the likelihood of different values for a continuous random variable. It doesn't give you the exact probability of a specific value but rather the relative likelihood of values within an interval. To find the probability of a continuous random variable falling within a specific range, you need to integrate the PDF over that range.\n",
    "\n",
    "Example: Normal Distribution\n",
    "The normal distribution is a common example of a continuous random variable. Its PDF is given by the bell-shaped curve formula:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Cumulative Density Function (CDF) is a fundamental concept in probability and statistics. It is a function that describes the cumulative probability of a random variable being less than or equal to a particular value. In other words, the CDF gives you the probability that a random variable takes on a value less than or equal to a specified threshold.\n",
    "Mathematically, for a random variable X, the CDF is denoted as F(x) and is defined as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "Example: Rolling a Fair Six-Sided Die\n",
    "Let's consider the case of rolling a fair six-sided die. The possible outcomes are integers 1 through 6. To calculate the CDF for this scenario:\n",
    "\n",
    "F(1) = P(X ≤ 1) = 1/6\n",
    "F(2) = P(X ≤ 2) = 2/6\n",
    "F(3) = P(X ≤ 3) = 3/6\n",
    "F(4) = P(X ≤ 4) = 4/6\n",
    "F(5) = P(X ≤ 5) = 5/6\n",
    "F(6) = P(X ≤ 6) = 6/6 = 1\n",
    "\n",
    "Why CDF is used:\n",
    "\n",
    "Cumulative Information: CDF provides a cumulative view of the probability distribution, allowing you to analyze the probabilities of values up to a certain threshold. It's especially useful when you want to know how likely it is to obtain values within a particular range.\n",
    "\n",
    "Quantile Estimation: CDF can be used to estimate percentiles or quantiles of the distribution. For example, you can find the median (50th percentile) by locating the value of x for which F(x) = 0.5.\n",
    "\n",
    "Hypothesis Testing: CDF is often used in hypothesis testing to assess whether observed data fits a particular distribution. By comparing the CDF of observed data to the CDF of a theoretical distribution, you can make statistical inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ea8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Height of Individuals: In populations, height often follows a normal distribution, with most people near the average height and fewer individuals at the extreme ends of the height spectrum.\n",
    "\n",
    "IQ Scores: Intelligence quotient (IQ) scores in a large population tend to approximate a normal distribution, with the majority of people clustered around the mean IQ.\n",
    "\n",
    "Measurement Errors: In scientific experiments, measurement errors are often assumed to be normally distributed because they result from a combination of many small random factors.\n",
    "\n",
    "Test Scores: In standardized tests like the SAT or GRE, the scores are often designed to follow a normal distribution, with a mean and standard deviation that have been predetermined.\n",
    "    \n",
    "parameters of the normal distribution relate to the shape of the distribution:\n",
    "\n",
    "Mean (μ): The mean (average) of the normal distribution represents the central value around which the data is centered. It is also the peak of the distribution, where the probability density is highest. Shifting the mean to the left or right will move the entire distribution along the x-axis without changing its shape.\n",
    "\n",
    "Standard Deviation (σ): The standard deviation measures the spread or dispersion of the data. A larger standard deviation results in a wider and flatter distribution, while a smaller standard deviation results in a narrower and taller distribution. It controls how much the data values tend to vary from the mean.\n",
    "\n",
    "Variance (σ²): Variance is the square of the standard deviation. It quantifies the average squared deviation from the mean. A higher variance indicates greater variability in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da88221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "The normal distribution, also known as the Gaussian distribution or the bell curve, is of paramount importance in statistics, data analysis, and various scientific fields. Its significance arises from several key factors:\n",
    "\n",
    "Common Natural Phenomenon: Many real-world phenomena and measurements naturally follow a normal distribution. This makes it a fundamental model for a wide range of processes and data, simplifying statistical analysis.\n",
    "\n",
    "Central Limit Theorem: The normal distribution plays a central role in the Central Limit Theorem (CLT), which states that the distribution of the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the underlying distribution of the variables. This property allows statisticians to make inferences about populations even when the population distribution is unknown.\n",
    "    \n",
    "Examples of real-life situations where the normal distribution is observed:\n",
    "\n",
    "Height of Individuals: In a large population, heights tend to follow a normal distribution, with most people close to the average height.\n",
    "\n",
    "IQ Scores: Intelligence quotient (IQ) scores in a population often exhibit a normal distribution, with most people having scores near the mean IQ.\n",
    "\n",
    "Blood Pressure: Blood pressure measurements in a population can be approximated by a normal distribution.\n",
    "\n",
    "Exam Scores: In a classroom, exam scores often follow a normal distribution, especially in large classes.\n",
    "\n",
    "Errors in Measurement: Measurement errors, such as errors in laboratory measurements or industrial quality control, are often normally distributed due to the combined effects of many small random factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3caa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f790f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "The Bernoulli distribution is a probability distribution that models a random experiment with exactly two possible outcomes, often referred to as \"success\" and \"failure.\" It's named after the Swiss mathematician Jacob Bernoulli. The distribution is characterized by a single parameter, denoted as \"p,\" which represents the probability of success.\n",
    "\n",
    "In a Bernoulli distribution:\n",
    "\n",
    "The random variable, often denoted as X, takes on one of two values: 1 (success) or 0 (failure).\n",
    "The probability mass function (PMF) is given by:\n",
    "P(X = 1) = p\n",
    "P(X = 0) = 1 - p\n",
    "\n",
    "Difference Between Bernoulli and Binomial Distributions:\n",
    "\n",
    "Number of Trials:\n",
    "Bernoulli Distribution: It models the outcome of a single trial or experiment with two possible outcomes.\n",
    "Binomial Distribution: It models the number of successes in a fixed number of independent Bernoulli trials.\n",
    "\n",
    "Random Variable:\n",
    "Bernoulli Distribution: It has a single random variable (X) that takes values 0 or 1.\n",
    "Binomial Distribution: It has a random variable (usually denoted as X) that represents the count of successes (1s) in a fixed number of trials (n).\n",
    "\n",
    "Parameters:\n",
    "Bernoulli Distribution: It has a single parameter p, representing the probability of success in a single trial.\n",
    "Binomial Distribution: It has two parameters: n (the number of trials) and p (the probability of success in each trial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4269249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56621181",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (X - μ) / σ\n",
    "z = (60 - 50) / 10\n",
    "z = 1.0\n",
    "P(Z > 1.0) = 1 - P(Z ≤ 1.0)\n",
    "Using a standard normal distribution table, you can find that P(Z ≤ 1.0) is approximately 0.8413.\n",
    "P(Z > 1.0) = 1 - 0.8413\n",
    "P(Z > 1.0) ≈ 0.1587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3faa8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "The uniform distribution is a probability distribution in which all values within a specified range are equally likely to occur. In other words, every outcome in the range has the same probability of occurring. The uniform distribution is characterized by two parameters: the lower limit (a) and the upper limit (b), which define the range of possible values.\n",
    "\n",
    "Here's an explanation of the uniform distribution with an example:\n",
    "\n",
    "Example: Uniform Distribution of a Fair Die Roll\n",
    "\n",
    "Consider rolling a fair six-sided die. The die has six faces, numbered from 1 to 6. Each face has an equal probability of landing face up, making it a uniform distribution over the range [1, 6].\n",
    "\n",
    "In this case:\n",
    "\n",
    "Lower Limit (a) = 1 (the minimum value on the die)\n",
    "Upper Limit (b) = 6 (the maximum value on the die)\n",
    "The probability mass function (PMF) of a uniform distribution between a and b is given by:\n",
    "\n",
    "P(X = x) = 1 / (b - a + 1), for x = a, a+1, a+2, ..., b\n",
    "\n",
    "For our example:\n",
    "\n",
    "P(X = 1) = 1 / (6 - 1 + 1) = 1/6\n",
    "P(X = 2) = 1 / (6 - 1 + 1) = 1/6\n",
    "P(X = 3) = 1 / (6 - 1 + 1) = 1/6\n",
    "P(X = 4) = 1 / (6 - 1 + 1) = 1/6\n",
    "P(X = 5) = 1 / (6 - 1 + 1) = 1/6\n",
    "P(X = 6) = 1 / (6 - 1 + 1) = 1/6\n",
    "Each outcome (rolling a specific number on the die) has a probability of 1/6, and all probabilities sum up to 1, as expected for a valid probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b92766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1330a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "The z-score, also known as the standard score or standard deviation score, is a statistical measure that quantifies how many standard deviations a particular data point is from the mean (average) of a dataset. It allows you to standardize data and compare data points from different distributions. The formula for calculating the z-score for a data point x in a dataset with mean μ and standard deviation σ is:\n",
    "\n",
    "z=(x-μ)/σ \n",
    "\n",
    "Here's the importance of the z-score in statistics:\n",
    "\n",
    "Standardization: The z-score standardizes data, which means it scales and shifts data points to have a mean of 0 and a standard deviation of 1. This standardization makes it easier to compare and analyze data from different sources or datasets.\n",
    "\n",
    "Outlier Detection: Z-scores are used to identify outliers or extreme data points. Data points with z-scores significantly higher or lower than the mean (typically beyond a certain threshold, like ±2 or ±3 standard deviations) may be considered outliers.\n",
    "\n",
    "Probability and Percentiles: Z-scores are used in the context of the standard normal distribution (with mean 0 and standard deviation 1) to calculate probabilities and percentiles. You can find the probability of a data point falling within a certain range or the percentile rank of a data point within a distribution using z-scores.\n",
    "    \n",
    "Quality Control: Z-scores are used in quality control to monitor the performance of manufacturing processes. Deviations from expected z-scores may indicate problems or defects in the process.\n",
    "\n",
    "Grading and Assessment: Z-scores are sometimes used in educational assessments to compare students' performance on standardized tests with a reference group.\n",
    "\n",
    "Normalization: In some cases, z-score normalization is used to bring different variables to a common scale, allowing for more meaningful comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b83baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental theorem in probability and statistics. It states that the distribution of the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the underlying distribution of the variables themselves. The CLT is a key concept in both theoretical and practical statistics.\n",
    "\n",
    "Large Sample Size: The CLT applies as the sample size (the number of random variables being summed or averaged) becomes sufficiently large. There is no specific threshold for what constitutes a \"large\" sample size, but in practice, sample sizes of 30 or greater are often considered sufficient.\n",
    "\n",
    "Independence: The random variables being summed or averaged must be independent of each other. This means that the outcome of one random variable does not influence the outcome of another.\n",
    "    \n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "Approximation of the Normal Distribution: The primary significance of the CLT is that it allows us to approximate the distribution of the sample mean (or sum) of a large sample from any population, regardless of the population's underlying distribution, as a normal distribution. This is extremely useful because normal distributions are well-understood and have many practical applications.\n",
    "\n",
    "Statistical Inference: The CLT is the basis for many common statistical inference techniques, including hypothesis testing, confidence interval estimation, and regression analysis. It enables statisticians to make inferences about population parameters based on sample statistics.\n",
    "\n",
    "Real-World Applications: In practice, data often exhibits deviations from ideal normality. However, thanks to the CLT, we can still make valid statistical inferences about populations because sample means tend to follow a normal distribution even when the individual data points do not.\n",
    "\n",
    "Sampling from Unknown Distributions: When the underlying distribution of a population is unknown, the CLT allows us to make statistical inferences without requiring knowledge of the population distribution. This is particularly useful in fields such as quality control, finance, and social sciences.\n",
    "\n",
    "Quality Assurance: In quality control and manufacturing, the CLT is used to monitor and control processes. It helps assess whether observed variations in measurements are within expected bounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06da56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics, and its applicability relies on several key assumptions. These assumptions help ensure that the theorem holds and that the distribution of the sample mean approaches a normal distribution. The assumptions of the Central Limit Theorem are as follows:\n",
    "\n",
    "Independence: The random variables being sampled must be independent of each other. This means that the outcome of one random variable should not be influenced by the outcome of another. Independence is crucial because it allows for the sum or average of these random variables to behave predictably.\n",
    "\n",
    "Identical Distribution: The random variables should have the same probability distribution, including the same mean (μ) and the same standard deviation (σ). In other words, they should be drawn from the same population and have the same underlying characteristics.\n",
    "\n",
    "Random Sampling: The samples should be drawn randomly from the population. This ensures that the samples are representative of the population and avoids systematic bias.\n",
    "\n",
    "Sample Size: The CLT assumes that the sample size is sufficiently large. While there is no strict rule for what constitutes a \"large\" sample size, a common guideline is that the sample size should generally be at least 30. Smaller sample sizes may still yield approximately normal distributions if the population itself is normally distributed.\n",
    "\n",
    "Finite Variance: The random variables should have a finite variance (σ²). This assumption ensures that the variance of the sample mean or sum approaches a finite value as the sample size increases.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
