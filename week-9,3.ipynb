{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deba99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb341537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        course_name  duration\n",
      "0      Data Science         2\n",
      "1  Machine Learning         3\n",
      "2          Big Data         6\n",
      "3     Data Engineer         4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "course_name    Big Data\n",
       "duration              6\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "course_name = [\"Data Science\", \"Machine Learning\", \"Big Data\", \"Data Engineer\"]\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {\"course_name\" : course_name, \"duration\" : duration})\n",
    "print(df)\n",
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3025d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc:\n",
    "It is label-based indexing, which means you use labels (row and column names) to select data.\n",
    "You specify the row and column labels explicitly.\n",
    "Inclusive on both ends (i.e., it includes the start and stop labels).\n",
    "Example: df.loc[row_label, column_label]\n",
    "df.loc[0, 'column_name']  \n",
    "\n",
    "iloc:\n",
    "It is integer-based indexing, which means you use integer positions (integer row and column indices) to select data.\n",
    "You specify the row and column indices as integers.\n",
    "Exclusive on the stop end (i.e., it includes the start index but excludes the stop index).\n",
    "Example: df.iloc[row_index, column_index]\n",
    "df.iloc[0, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd40a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        course_name  duration\n",
      "3     Data Engineer         4\n",
      "0      Data Science         2\n",
      "1  Machine Learning         3\n",
      "2          Big Data         6\n",
      "\n",
      "Output for new_df.loc[2]:\n",
      "course_name    Big Data\n",
      "duration              6\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Output for new_df.iloc[2]:\n",
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df.reindex(reindex)\n",
    "print(new_df)\n",
    "output_loc = new_df.loc[2]\n",
    "print(\"\\nOutput for new_df.loc[2]:\")\n",
    "print(output_loc)\n",
    "\n",
    "# Output for new_df.iloc[2]\n",
    "output_iloc = new_df.iloc[2]\n",
    "print(\"\\nOutput for new_df.iloc[2]:\")\n",
    "print(output_iloc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708316a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "042a9891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.489386\n",
      "column_2    0.530046\n",
      "column_3    0.414738\n",
      "column_4    0.584742\n",
      "column_5    0.598683\n",
      "column_6    0.678245\n",
      "dtype: float64\n",
      "\n",
      "Standard deviation of 'column_2':\n",
      "0.35218771095494267\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "std_dev_column_2 = df1['column_2'].std()\n",
    "print(\"\\nStandard deviation of 'column_2':\")\n",
    "print(std_dev_column_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebcb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a866cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unsupported operand type(s) for +: 'float' and 'str'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "df1.loc[2, 'column_2'] = 'String Data'\n",
    "try:\n",
    "    column_2_mean = df1['column_2'].mean()\n",
    "    print(\"Mean of 'column_2':\", column_2_mean)\n",
    "except TypeError as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52cafa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "2023-01-01   -0.366740\n",
      "2023-01-02   -0.109041\n",
      "2023-01-03    0.906380\n",
      "2023-01-04   -0.215070\n",
      "2023-01-05    0.026354\n",
      "2023-01-06    0.203718\n",
      "2023-01-07   -0.443437\n",
      "2023-01-08   -0.085473\n",
      "2023-01-09   -0.938335\n",
      "2023-01-10   -0.622215\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "3-Day Simple Moving Average:\n",
      "2023-01-01         NaN\n",
      "2023-01-02         NaN\n",
      "2023-01-03    0.143533\n",
      "2023-01-04    0.194090\n",
      "2023-01-05    0.239221\n",
      "2023-01-06    0.005001\n",
      "2023-01-07   -0.071122\n",
      "2023-01-08   -0.108397\n",
      "2023-01-09   -0.489082\n",
      "2023-01-10   -0.548674\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "''''Rolling Window: A rolling window is a fixed-size subset of the data that moves or \"rolls\" through the dataset one step at a time. You can specify the window size and the rolling step, which allows you to control how the window moves through the data.\n",
    "\n",
    "Aggregation and Transformation: Window functions can be used for both aggregation and transformation of data. Aggregation functions, like mean, sum, or count, calculate summary statistics over the window. Transformation functions can modify the data within the window, such as applying custom functions or smoothing data.\n",
    "\n",
    "Types of Window Functions: There are various types of window functions available in pandas, including:\n",
    "\n",
    "Aggregation Functions: These functions compute a single aggregated value for each window. Some common aggregation functions include:\n",
    "\n",
    "mean(): Calculates the mean (average) of values in the window.\n",
    "sum(): Computes the sum of values in the window.\n",
    "max(): Finds the maximum value in the window.\n",
    "min(): Finds the minimum value in the window.\n",
    "count(): Counts the number of non-null values in the window.\n",
    "\n",
    "Expanding Functions: These functions consider all data points from the start of the data up to the current position. Some examples include cumsum() (cumulative sum) and cumprod() (cumulative product).\n",
    "\n",
    "Exponential Moving Average (EMA): A specialized type of rolling window function that assigns exponentially decreasing weights to older data points, giving more weight to recent data. Useful for smoothing time series data.\n",
    "\n",
    "Quantile and Rank-based Functions: These functions calculate quantiles (e.g., median, quartiles) and rank-based statistics within the window.'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.Series(np.random.randn(10), index=pd.date_range(start='2023-01-01', periods=10, freq='D'))\n",
    "sma = data.rolling(window=3).mean()\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "print(\"\\n3-Day Simple Moving Average:\")\n",
    "print(sma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e41d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month and Year: September 2023\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "current_datetime = datetime.now()\n",
    "current_month = current_datetime.month\n",
    "current_year = current_datetime.year\n",
    "current_date = pd.to_datetime(f\"{current_year}-{current_month:02d}-01\")\n",
    "print(\"Current Month and Year:\", current_date.strftime('%B %Y'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56102db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "686442eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):\n",
      "Date 1: 2023-07-22\n",
      "\n",
      "Enter the second date (YYYY-MM-DD):\n",
      "Date 2: 2023-07-24\n",
      "\n",
      "Time Difference:\n",
      "Days: 2 days\n",
      "Hours: 0 hours\n",
      "Minutes: 0 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def get_valid_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            date_input = input(prompt)\n",
    "            date = pd.to_datetime(date_input)\n",
    "            return date\n",
    "        except ValueError:\n",
    "            print(\"Invalid date format. Please enter a date in YYYY-MM-DD format.\")\n",
    "\n",
    "print(\"Enter the first date (YYYY-MM-DD):\")\n",
    "date1 = get_valid_date_input(\"Date 1: \")\n",
    "\n",
    "print(\"\\nEnter the second date (YYYY-MM-DD):\")\n",
    "date2 = get_valid_date_input(\"Date 2: \")\n",
    "time_difference = date2 - date1\n",
    "\n",
    "days = time_difference.days\n",
    "hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "minutes, _ = divmod(remainder, 60)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nTime Difference:\")\n",
    "print(f\"Days: {days} days\")\n",
    "print(f\"Hours: {hours} hours\")\n",
    "print(f\"Minutes: {minutes} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63474e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6cf3ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the CSV file path: Iris.csv\n",
      "Enter the column name to convert to categorical: SepalLengthCm\n",
      "Enter the category order (comma-separated, e.g., 'Low,Medium,High'): High\n",
      "\n",
      "Sorted Data:\n",
      "      Id SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
      "0      1           NaN           3.5            1.4           0.2   \n",
      "1      2           NaN           3.0            1.4           0.2   \n",
      "2      3           NaN           3.2            1.3           0.2   \n",
      "3      4           NaN           3.1            1.5           0.2   \n",
      "4      5           NaN           3.6            1.4           0.2   \n",
      "..   ...           ...           ...            ...           ...   \n",
      "145  146           NaN           3.0            5.2           2.3   \n",
      "146  147           NaN           2.5            5.0           1.9   \n",
      "147  148           NaN           3.0            5.2           2.0   \n",
      "148  149           NaN           3.4            5.4           2.3   \n",
      "149  150           NaN           3.0            5.1           1.8   \n",
      "\n",
      "            Species  \n",
      "0       Iris-setosa  \n",
      "1       Iris-setosa  \n",
      "2       Iris-setosa  \n",
      "3       Iris-setosa  \n",
      "4       Iris-setosa  \n",
      "..              ...  \n",
      "145  Iris-virginica  \n",
      "146  Iris-virginica  \n",
      "147  Iris-virginica  \n",
      "148  Iris-virginica  \n",
      "149  Iris-virginica  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def convert_to_categorical(file_path, column_name, category_order):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "    sorted_df = df.sort_values(by=column_name)\n",
    "    \n",
    "    return sorted_df\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "category_order_str = input(\"Enter the category order (comma-separated, e.g., 'Low,Medium,High'): \")\n",
    "category_order = category_order_str.split(',')\n",
    "sorted_data = convert_to_categorical(file_path, column_name, category_order)\n",
    "print(\"\\nSorted Data:\")\n",
    "print(sorted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e77d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_sales_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    pivot_df = df.pivot(index='Date', columns='ProductCategory', values='Sales').fillna(0)\n",
    "    ax = pivot_df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.title('Stacked Bar Chart of Sales by Product Category Over Time')\n",
    "    plt.legend(title='Product Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n",
    "file_path = input(\"Enter the CSV file path containing sales data: \")\n",
    "visualize_sales_data(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba79989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = input(\"Enter the file path of the CSV file containing student data: \")\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "    exit()\n",
    "mean_score = df['Test Score'].mean()\n",
    "median_score = df['Test Score'].median()\n",
    "mode_scores = df['Test Score'].mode().tolist()\n",
    "result_table = pd.DataFrame({\n",
    "    'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "    'Value': [mean_score, median_score, ', '.join(map(str, mode_scores))]\n",
    "})\n",
    "\n",
    "print(result_table.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ecca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
